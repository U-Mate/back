require('dotenv').config();
const express = require('express');
const expressWs = require('express-ws');
const WebSocket = require('ws');
const cors = require('cors');
const mariaDB = require("mysql2/promise");

const app = express();
expressWs(app);

// CORS ì„¤ì •
app.use(cors({
  origin: [process.env.LOCALHOST, process.env.MY_HOST],
  credentials: true
}));

app.use(express.json());

// ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
const db = mariaDB.createPool({
    host: process.env.DB_HOST,
    port: process.env.DB_PORT,
    user: process.env.DB_USER,
    password: process.env.DB_PASSWORD,
    database: process.env.DB_SCHEMA
});

// ì„œë¹„ìŠ¤ ì •ë³´ë¥¼ ë¡œë“œí•˜ì—¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
async function loadServiceKnowledgeBase() {
    try {
        // ëª¨ë“  ì„œë¹„ìŠ¤ ì •ë³´ ë¡œë“œ
        const [services] = await db.execute(`
            SELECT service_name, description, features, usage_guide, category, contact_info
            FROM services 
            ORDER BY category, service_name
        `);

        // FAQ ì •ë³´ ë¡œë“œ  
        const [faqs] = await db.execute(`
            SELECT question, answer, category, keywords
            FROM faq 
            ORDER BY frequency DESC, category
        `);

        // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ ìƒì„±
        let knowledgeBase = "\n\n=== UMate ì„œë¹„ìŠ¤ ì •ë³´ ë°ì´í„°ë² ì´ìŠ¤ ===\n\n";
        
        // ì„œë¹„ìŠ¤ ì •ë³´
        knowledgeBase += "ğŸ“‹ ì œê³µ ì„œë¹„ìŠ¤ ëª©ë¡:\n";
        let currentCategory = '';
        services.forEach(service => {
            if (service.category !== currentCategory) {
                currentCategory = service.category;
                knowledgeBase += `\n[${service.category}]\n`;
            }
            knowledgeBase += `â€¢ ${service.service_name}: ${service.description}\n`;
            if (service.features) {
                knowledgeBase += `  - ì£¼ìš” ê¸°ëŠ¥: ${service.features}\n`;
            }
            if (service.usage_guide) {
                knowledgeBase += `  - ì´ìš© ë°©ë²•: ${service.usage_guide}\n`;
            }
            if (service.contact_info) {
                knowledgeBase += `  - ë¬¸ì˜ì²˜: ${service.contact_info}\n`;
            }
        });

        // FAQ ì •ë³´
        knowledgeBase += "\nâ“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸:\n";
        let faqCategory = '';
        faqs.forEach(faq => {
            if (faq.category !== faqCategory) {
                faqCategory = faq.category;
                knowledgeBase += `\n[${faq.category} ê´€ë ¨]\n`;
            }
            knowledgeBase += `Q: ${faq.question}\n`;
            knowledgeBase += `A: ${faq.answer}\n\n`;
        });

        knowledgeBase += "=== ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ë ===\n\n";
        
        return knowledgeBase;
        
    } catch (error) {
        console.error('ì„œë¹„ìŠ¤ ì •ë³´ ë¡œë“œ ì˜¤ë¥˜:', error);
        return "\n\nâ€» í˜„ì¬ ì„œë¹„ìŠ¤ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n";
    }
}

// ì‚¬ìš©ìë³„ ì—°ê²° ì €ì¥
const userConnections = new Map();
let serviceKnowledgeBase = '';

// ì„œë²„ ì‹œì‘ ì‹œ ì„œë¹„ìŠ¤ ì •ë³´ ë¡œë“œ
loadServiceKnowledgeBase().then(knowledge => {
    serviceKnowledgeBase = knowledge;
    console.log('ğŸ“š ì„œë¹„ìŠ¤ ì§€ì‹ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ');
}).catch(console.error);

// ì£¼ê¸°ì ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì •ë³´ ì—…ë°ì´íŠ¸ (1ì‹œê°„ë§ˆë‹¤)
setInterval(async () => {
    try {
        serviceKnowledgeBase = await loadServiceKnowledgeBase();
        console.log('ğŸ”„ ì„œë¹„ìŠ¤ ì§€ì‹ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ë¨');
    } catch (error) {
        console.error('ì§€ì‹ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜:', error);
    }
}, 60 * 60 * 1000); // 1ì‹œê°„

// GPT-4o mini Realtime WebSocket ì±—ë´‡ (ì •ì  ì»¨í…ìŠ¤íŠ¸)
app.ws('/ws/realtime-chat', (clientWs, req) => {
  const sessionId = req.query.sessionId || `session_${Date.now()}_${Math.random()}`;
  const userId = req.query.userId || null;
  
  console.log(`ğŸ”— ìƒˆë¡œìš´ Realtime ì—°ê²°: ${sessionId}, ì‚¬ìš©ì: ${userId || 'ê²ŒìŠ¤íŠ¸'}`);

  // OpenAI Realtime API ì—°ê²°
  const openaiWs = new WebSocket('wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01', {
    headers: {
      'Authorization': `Bearer ${process.env.CHATBOT_API}`,
      'OpenAI-Beta': 'realtime=v1'
    }
  });

  // ì—°ê²° ì €ì¥
  userConnections.set(sessionId, { clientWs, openaiWs, userId });

  // OpenAI ì—°ê²° ì„±ê³µ ì‹œ ì„¸ì…˜ ì„¤ì •
  openaiWs.on('open', () => {
    console.log(`OpenAI Realtime API ì—°ê²°ë¨: ${sessionId}`);
    
    // ğŸ”¥ í•µì‹¬: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì „ì²´ ì„œë¹„ìŠ¤ ì •ë³´ í¬í•¨
    const systemInstructions = `ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” UMateì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ëŒ€í•™êµ ì„œë¹„ìŠ¤ì™€ ê´€ë ¨ëœ ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œê·¼í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

${serviceKnowledgeBase}

ë‹µë³€ ì§€ì¹¨:
1. ìœ„ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ë¥¼ ì •í™•íˆ í™œìš©í•˜ì—¬ ë‹µë³€
2. ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì„œë¹„ìŠ¤/FAQ ë‚´ìš© ìš°ì„  ì œê³µ
3. ë‹¨ê³„ë³„ ì´ìš© ë°©ë²•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´
4. ì—°ë½ì²˜ë‚˜ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° í•´ë‹¹ ì •ë³´ ì œê³µ
5. ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ í•œêµ­ì–´ ë‹µë³€
6. í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” "ì •í™•í•œ ì •ë³´ëŠ” í•´ë‹¹ ë¶€ì„œì— ë¬¸ì˜í•˜ì„¸ìš”"ë¼ê³  ì•ˆë‚´

ì‚¬ìš©ìê°€ ì„œë¹„ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´, ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì•„ì„œ ì •í™•í•˜ê³  ìì„¸íˆ ë‹µë³€í•´ì£¼ì„¸ìš”.`;

    // ì„¸ì…˜ ì„¤ì • (ìŒì„± + í…ìŠ¤íŠ¸ ì§€ì›)
    openaiWs.send(JSON.stringify({
      type: 'session.update',
      session: {
        modalities: ['text', 'audio'],
        instructions: systemInstructions,
        voice: 'alloy',
        input_audio_format: 'pcm16',
        output_audio_format: 'pcm16',
        input_audio_transcription: {
          model: 'whisper-1'
        },
        turn_detection: {
          type: 'server_vad',
          threshold: 0.5,
          prefix_padding_ms: 300,
          silence_duration_ms: 500
        },
        tools: [],
        tool_choice: 'auto',
        temperature: 0.7,
        max_response_output_tokens: 4096
      }
    }));

    // í´ë¼ì´ì–¸íŠ¸ì— ì—°ê²° ì„±ê³µ ì•Œë¦¼
    clientWs.send(JSON.stringify({
      type: 'connection',
      status: 'connected',
      message: 'ìœ ì‹ì´(UMate AI)ì™€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€í•™ ì„œë¹„ìŠ¤ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!',
      sessionId: sessionId,
      capabilities: {
        text: true,
        audio: true,
        database: true,
        knowledgeBase: 'loaded'
      }
    }));
  });

  // ë‚˜ë¨¸ì§€ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼
  openaiWs.on('message', (data) => {
    try {
      const event = JSON.parse(data.toString());
      
      switch (event.type) {
        case 'session.created':
          console.log('Realtime ì„¸ì…˜ ìƒì„±ë¨');
          break;

        case 'session.updated':
          console.log('Realtime ì„¸ì…˜ ì—…ë°ì´íŠ¸ë¨');
          break;

        case 'input_audio_buffer.speech_started':
          clientWs.send(JSON.stringify({
            type: 'speech_started',
            message: 'ğŸ¤ ìŒì„±ì„ ë“£ê³  ìˆìŠµë‹ˆë‹¤...'
          }));
          break;

        case 'input_audio_buffer.speech_stopped':
          clientWs.send(JSON.stringify({
            type: 'speech_stopped',
            message: 'ğŸ”„ ìŒì„±ì„ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...'
          }));
          break;

        case 'conversation.item.input_audio_transcription.completed':
          clientWs.send(JSON.stringify({
            type: 'transcription_complete',
            transcription: event.transcript,
            item_id: event.item_id
          }));
          break;

        case 'conversation.item.created':
          if (event.item.type === 'message' && event.item.role === 'assistant') {
            clientWs.send(JSON.stringify({
              type: 'assistant_message_start',
              message: 'ğŸ’¡ ì„œë¹„ìŠ¤ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤...'
            }));
          }
          break;

        case 'response.audio.delta':
          clientWs.send(JSON.stringify({
            type: 'audio_delta',
            audio: event.delta,
            response_id: event.response_id,
            item_id: event.item_id
          }));
          break;

        case 'response.audio_transcript.delta':
          clientWs.send(JSON.stringify({
            type: 'audio_transcript_delta',
            delta: event.delta,
            response_id: event.response_id,
            item_id: event.item_id
          }));
          break;

        case 'response.text.delta':
          clientWs.send(JSON.stringify({
            type: 'text_delta',
            delta: event.delta,
            response_id: event.response_id,
            item_id: event.item_id
          }));
          break;

        case 'response.text.done':
        case 'response.audio_transcript.done':
          clientWs.send(JSON.stringify({
            type: 'text_done',
            text: event.text || event.transcript,
            response_id: event.response_id,
            item_id: event.item_id
          }));
          break;

        case 'response.done':
          clientWs.send(JSON.stringify({
            type: 'response_complete',
            response: event.response
          }));
          break;

        case 'error':
          console.error('OpenAI Realtime API ì˜¤ë¥˜:', event.error);
          clientWs.send(JSON.stringify({
            type: 'error',
            error: event.error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
          }));
          break;

        default:
          clientWs.send(JSON.stringify({
            type: 'openai_event',
            event: event
          }));
      }
    } catch (error) {
      console.error('OpenAI ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', error);
    }
  });

  // í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
  clientWs.on('message', async (message) => {
    try {
      const data = JSON.parse(message);
      
      switch (data.type) {
        case 'user_message':
          if (openaiWs.readyState === WebSocket.OPEN) {
            openaiWs.send(JSON.stringify({
              type: 'conversation.item.create',
              item: {
                type: 'message',
                role: 'user',
                content: [
                  {
                    type: 'input_text',
                    text: data.message
                  }
                ]
              }
            }));

            openaiWs.send(JSON.stringify({
              type: 'response.create',
              response: {
                modalities: ['text'],
                instructions: 'ì„œë¹„ìŠ¤ ì§€ì‹ë² ì´ìŠ¤ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.'
              }
            }));
          }
          break;

        case 'audio_data':
          if (openaiWs.readyState === WebSocket.OPEN) {
            openaiWs.send(JSON.stringify({
              type: 'input_audio_buffer.append',
              audio: data.audio
            }));
          }
          break;

        case 'audio_commit':
          if (openaiWs.readyState === WebSocket.OPEN) {
            openaiWs.send(JSON.stringify({
              type: 'input_audio_buffer.commit'
            }));

            openaiWs.send(JSON.stringify({
              type: 'response.create',
              response: {
                modalities: ['audio', 'text'],
                instructions: 'ì„œë¹„ìŠ¤ ì§€ì‹ë² ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ í•œêµ­ì–´ë¡œ ìŒì„±ê³¼ í…ìŠ¤íŠ¸ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.'
              }
            }));
          }
          break;

        case 'voice_change':
          if (openaiWs.readyState === WebSocket.OPEN) {
            openaiWs.send(JSON.stringify({
              type: 'session.update',
              session: {
                voice: data.voice
              }
            }));
          }
          break;

        default:
          console.log('ì•Œ ìˆ˜ ì—†ëŠ” í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ íƒ€ì…:', data.type);
      }
    } catch (error) {
      console.error('í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', error);
      clientWs.send(JSON.stringify({
        type: 'error',
        error: 'ë©”ì‹œì§€ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.'
      }));
    }
  });

  // ì—°ê²° ì¢…ë£Œ ì²˜ë¦¬
  openaiWs.on('error', (error) => {
    console.error('OpenAI Realtime API ì˜¤ë¥˜:', error);
    clientWs.send(JSON.stringify({
      type: 'error',
      error: 'OpenAI ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
    }));
  });

  openaiWs.on('close', () => {
    console.log(`OpenAI Realtime API ì—°ê²° ì¢…ë£Œ: ${sessionId}`);
    clientWs.send(JSON.stringify({
      type: 'connection',
      status: 'disconnected',
      message: 'OpenAI ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
    }));
  });

  clientWs.on('close', () => {
    console.log(`í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ: ${sessionId}`);
    if (openaiWs.readyState === WebSocket.OPEN) {
      openaiWs.close();
    }
    userConnections.delete(sessionId);
  });

  clientWs.on('error', (error) => {
    console.error('í´ë¼ì´ì–¸íŠ¸ WebSocket ì˜¤ë¥˜:', error);
  });
});

// API: ì§€ì‹ë² ì´ìŠ¤ ìƒˆë¡œê³ ì¹¨
app.post('/api/knowledge/refresh', async (req, res) => {
  try {
    serviceKnowledgeBase = await loadServiceKnowledgeBase();
    res.json({
      success: true,
      message: 'ì„œë¹„ìŠ¤ ì§€ì‹ë² ì´ìŠ¤ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.',
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: 'ì§€ì‹ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
    });
  }
});

// API: í˜„ì¬ ì§€ì‹ë² ì´ìŠ¤ í™•ì¸
app.get('/api/knowledge/status', (req, res) => {
  res.json({
    loaded: !!serviceKnowledgeBase,
    size: serviceKnowledgeBase.length,
    lastUpdated: new Date().toISOString(),
    preview: serviceKnowledgeBase.substring(0, 500) + '...'
  });
});

const PORT = process.env.PORT || 3004;
app.listen(PORT, () => {
  console.log(`ğŸš€ UMate ì •ì  ì§€ì‹ë² ì´ìŠ¤ Realtime ì±—ë´‡ì´ http://localhost:${PORT} ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.`);
  console.log(`ğŸ“¡ WebSocket: ws://localhost:${PORT}/ws/realtime-chat`);
  console.log(`ğŸ”„ ì§€ì‹ë² ì´ìŠ¤ ìƒˆë¡œê³ ì¹¨: POST /api/knowledge/refresh`);
  console.log(`ğŸ“Š ì§€ì‹ë² ì´ìŠ¤ ìƒíƒœ: GET /api/knowledge/status`);
  console.log(`ğŸ“š ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì „ì²´ ì„œë¹„ìŠ¤ ì •ë³´ í¬í•¨`);
});

module.exports = app; 